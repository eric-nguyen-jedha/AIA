pipeline {
    agent {
        docker {
            image 'python:3.10-slim'
            args '-u root:root'
        }
    }
    
    environment {
        WORK_DIR = "BLOC_04"
        REPORT_DIR = "${WORK_DIR}/reports"
        UNIT_REPORT = "${REPORT_DIR}/unit"
        ML_REPORT = "${REPORT_DIR}/ml"
        INTEGRATION_REPORT = "${REPORT_DIR}/integration"
    }
    
    stages {
        stage('Install dependencies') {
            steps {
                dir("${WORK_DIR}") {
                    sh '''
                        apt-get update && apt-get install -y --no-install-recommends gcc
                        pip install --upgrade pip
                        pip install -r requirements.txt
                    '''
                }
            }
        }
        
        stage('Lint Code') {
            steps {
                dir("${WORK_DIR}") {
                    sh '''
                        echo "üîç V√©rification qualit√© du code..."
                        flake8 dags/ dags_ml/ --max-line-length=120 --extend-ignore=E501,W503 --count || true
                        pylint dags/*.py dags_ml/*.py --disable=C,R --exit-zero || true
                    '''
                }
            }
        }
        
        stage('Validate DAGs') {
            steps {
                dir("${WORK_DIR}") {
                    sh '''
                        echo "‚úÖ Validation syntaxe des DAGs..."
                        export PYTHONPATH=$PYTHONPATH:$WORKSPACE/${WORK_DIR}/plugins
                        python tests/ml/validate_dags.py || exit 1
                    '''
                }
            }
        }
        
        stage('Run unit tests - Data Pipeline') {
            steps {
                dir("${WORK_DIR}") {
                    sh '''
                        echo "üß™ Tests unitaires - Pipeline de donn√©es..."
                        export PYTHONPATH=$PYTHONPATH:$WORKSPACE/${WORK_DIR}/plugins
                        mkdir -p reports/unit
                        pytest tests/unit \
                            --junitxml=reports/unit/report.xml \
                            --html=reports/unit/report.html \
                            --self-contained-html \
                            -v
                    '''
                }
            }
        }
        
        stage('Run unit tests - ML Pipeline') {
            steps {
                dir("${WORK_DIR}") {
                    sh '''
                        echo "üß™ Tests unitaires - Pipeline ML..."
                        export PYTHONPATH=$PYTHONPATH:$WORKSPACE/${WORK_DIR}/plugins:$WORKSPACE/${WORK_DIR}/dags_ml
                        mkdir -p reports/ml
                        pytest tests/ml/test_weather_dags.py tests/ml/test_training_pipeline.py \
                            -m "not integration" \
                            --junitxml=reports/ml/report.xml \
                            --html=reports/ml/report.html \
                            --self-contained-html \
                            --cov=dags_ml \
                            --cov-report=xml:reports/ml/coverage.xml \
                            --cov-report=html:reports/ml/coverage_html \
                            -v
                    '''
                }
            }
        }
        
        stage('Run integration tests - ML') {
            steps {
                dir("${WORK_DIR}") {
                    sh '''
                        echo "üîó Tests d'int√©gration - ML..."
                        export PYTHONPATH=$PYTHONPATH:$WORKSPACE/${WORK_DIR}/plugins:$WORKSPACE/${WORK_DIR}/dags_ml
                        mkdir -p reports/integration
                        pytest tests/ml \
                            -m "integration" \
                            --junitxml=reports/integration/report.xml \
                            --html=reports/integration/report.html \
                            --self-contained-html \
                            -v || true
                    '''
                }
            }
        }
        
        stage('Generate Test Summary') {
            steps {
                dir("${WORK_DIR}") {
                    script {
                        // Cr√©er un fichier HTML avec le r√©sum√© des tests
                        sh '''
                            mkdir -p reports/summary
                            cat > reports/summary/summary.html << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .summary { background: #e8f5e9; padding: 20px; border-radius: 5px; margin: 20px 0; }
        table { border-collapse: collapse; width: 100%; }
        th { background-color: #4CAF50; color: white; padding: 10px; }
        td { border: 1px solid #ddd; padding: 10px; }
        tr:nth-child(even) { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <h2>üìä R√©sum√© des Tests</h2>
    <div class="summary">
        <h3>‚úÖ Tous les tests sont pass√©s avec succ√®s !</h3>
    </div>
    <table>
        <tr><th>Cat√©gorie</th><th>Description</th></tr>
        <tr><td>tests.unit</td><td>Tests unitaires - Data Pipeline</td></tr>
        <tr><td>tests.ml.test_weather_dags</td><td>Tests - Pr√©diction m√©t√©o</td></tr>
        <tr><td>tests.ml.test_training_pipeline</td><td>Tests - Pipeline ML</td></tr>
    </table>
    <p>Consultez les rapports d√©taill√©s dans Jenkins pour plus d'informations.</p>
</body>
</html>
EOF
                        '''
                    }
                }
            }
        }
        
        stage('Publish reports') {
            steps {
                // Rapports JUnit
                junit allowEmptyResults: true, testResults: "${REPORT_DIR}/**/report.xml"
                
                // Rapports HTML - Tests unitaires (data pipeline)
                publishHTML(target: [
                    reportDir: "${UNIT_REPORT}",
                    reportFiles: "report.html",
                    reportName: "Unit Tests - Data Pipeline",
                    keepAll: true,
                    alwaysLinkToLastBuild: true
                ])
                
                // Rapports HTML - Tests unitaires ML
                publishHTML(target: [
                    reportDir: "${ML_REPORT}",
                    reportFiles: "report.html",
                    reportName: "Unit Tests - ML Pipeline",
                    keepAll: true,
                    alwaysLinkToLastBuild: true
                ])
                
                // Rapport de couverture ML
                publishHTML(target: [
                    reportDir: "${ML_REPORT}/coverage_html",
                    reportFiles: "index.html",
                    reportName: "Coverage Report - ML",
                    keepAll: true,
                    alwaysLinkToLastBuild: true
                ])
                
                // Rapports HTML - Tests d'int√©gration
                publishHTML(target: [
                    reportDir: "${INTEGRATION_REPORT}",
                    reportFiles: "report.html",
                    reportName: "Integration Tests - ML",
                    keepAll: true,
                    alwaysLinkToLastBuild: true,
                    allowMissing: true
                ])
                
                // Publier le r√©sum√©
                publishHTML(target: [
                    reportDir: "${REPORT_DIR}/summary",
                    reportFiles: "summary.html",
                    reportName: "Test Summary",
                    keepAll: true,
                    alwaysLinkToLastBuild: true
                ])
            }
        }
    }
    
    post {
    success {
        echo "‚úÖ All tests passed! Starting email notification process..."
        script {
            // D√©finition d'une fonction pour parser les rapports de mani√®re robuste
            def getTestCount(String reportPath) {
                try {
                    // V√©rifier si le fichier existe avant de tenter de le lire
                    if (!fileExists(reportPath)) {
                        echo "‚ö†Ô∏è Fichier de rapport introuvable √† l'emplacement : ${reportPath}"
                        return 0
                    }

                    echo "üìÑ Lecture du fichier de rapport : ${reportPath}"
                    def reportContent = readFile(reportPath)
                    
                    // Si le fichier est vide, retourner 0
                    if (reportContent.trim().isEmpty()) {
                        echo "‚ö†Ô∏è Le fichier de rapport est vide : ${reportPath}"
                        return 0
                    }

                    // Utiliser XmlSlurper pour une analyse XML fiable
                    def reportXml = new groovy.util.XmlSlurper().parseText(reportContent)
                    
                    // Extraire le nombre de tests. L'attribut 'tests' est sur la balise <testsuite>
                    // Pytest encapsule souvent <testsuite> dans une balise <testsuites>
                    def testCount = reportXml.testsuite.'@tests'.sum { it.toInteger() }
                    
                    echo "üìä Nombre de tests trouv√©s dans ${reportPath} : ${testCount}"
                    return testCount

                } catch (Exception e) {
                    echo "‚ùå Erreur lors de l'analyse du fichier XML ${reportPath}."
                    echo "   Message d'erreur : ${e.getMessage()}"
                    return 0
                }
            }

            // Appeler la fonction pour chaque rapport
            def unitTests = getTestCount("${REPORT_DIR}/unit/report.xml")
            def mlTests = getTestCount("${REPORT_DIR}/ml/report.xml")
            def integrationTests = getTestCount("${REPORT_DIR}/integration/report.xml")
            
            emailext(
                subject: "‚úÖ Tests r√©ussis - ${env.JOB_NAME} #${env.BUILD_NUMBER}",
                body: """
                    <html>
                    <body>
                        <h2>‚úÖ Tests r√©ussis</h2>
                        <p><b>Projet</b> : ${env.JOB_NAME}</p>
                        <p><b>Build</b> : #${env.BUILD_NUMBER}</p>
                        
                        <h3>üìä R√©sum√© des tests</h3>
                        <ul>
                            <li>Tests unitaires - Data Pipeline : ${unitTests} tests</li>
                            <li>Tests unitaires - ML Pipeline : ${mlTests} tests</li>
                            <li>Tests d'int√©gration : ${integrationTests} tests</li>
                        </ul>
                        
                        <h3>üìÑ Rapports</h3>
                        <ul>
                            <li><a href="${env.BUILD_URL}Unit_20Tests_20-_20Data_20Pipeline/">Tests Data Pipeline</a></li>
                            <li><a href="${env.BUILD_URL}Unit_20Tests_20-_20ML_20Pipeline/">Tests ML Pipeline</a></li>
                            <li><a href="${env.BUILD_URL}Coverage_20Report_20-_20ML/">Couverture ML</a></li>
                            <li><a href="${env.BUILD_URL}Integration_20Tests_20-_20ML/">Tests Int√©gration</a></li>
                        </ul>
                        
                        <p><i>Tous les tests ont √©t√© ex√©cut√©s avec succ√®s ! üéâ</i></p>
                        
                        <p>Cordialement,<br/>Jenkins CI</p>
                    </body>
                    </html>
                """,
                to: 'enguyen.fr@gmail.com',
                from: 'enguyen.fr@gmail.com',
                replyTo: 'enguyen.fr@gmail.com',
                mimeType: 'text/html'
            )
        }
    }
    
        
        failure {
            echo "‚ùå Some tests failed."
            script {
                emailext(
                    subject: "‚ùå √âchec des tests - ${env.JOB_NAME} #${env.BUILD_NUMBER}",
                    body: """
                        <html>
                        <body>
                            <h2>‚ùå √âchec des tests</h2>
                            <p><b>Projet</b> : ${env.JOB_NAME}</p>
                            <p><b>Build</b> : #${env.BUILD_NUMBER}</p>
                            
                            <h3>‚ö†Ô∏è Action requise</h3>
                            <p>Un ou plusieurs tests ont √©chou√©. Merci de consulter les rapports ci-dessous :</p>
                            
                            <h3>üìÑ Rapports</h3>
                            <ul>
                                <li><a href="${env.BUILD_URL}Unit_20Tests_20-_20Data_20Pipeline/">Tests Data Pipeline</a></li>
                                <li><a href="${env.BUILD_URL}Unit_20Tests_20-_20ML_20Pipeline/">Tests ML Pipeline</a></li>
                                <li><a href="${env.BUILD_URL}Integration_20Tests_20-_20ML/">Tests Int√©gration</a></li>
                                <li><a href="${env.BUILD_URL}console">Console Output</a></li>
                            </ul>
                            
                            <p><b>Merci de corriger les erreurs d√®s que possible.</b></p>
                            
                            <p>Cordialement,<br/>Jenkins CI</p>
                        </body>
                        </html>
                    """,
                    to: 'enguyen.fr@gmail.com',
                    from: 'enguyen.fr@gmail.com',
                    replyTo: 'enguyen.fr@gmail.com',
                    mimeType: 'text/html'
                )
            }
        }
        
        always {
            echo "üßπ Nettoyage..."
            cleanWs()
        }
    }
}
