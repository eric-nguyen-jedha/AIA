# Pipeline de DÃ©tection de Fraude avec Airflow, XGBoost et MLflow

Ce projet implÃ©mente un **pipeline automatisÃ© de dÃ©tection de fraude** en deux Ã©tapes :
1. **VÃ©rification de la qualitÃ© des donnÃ©es** (Drift, tests statistiques) avec Evidently.
2. **EntraÃ®nement d'un modÃ¨le XGBoost** et suivi des expÃ©riences avec MLflow.

Le pipeline est orchestrÃ© avec **Apache Airflow**, et les artefacts sont stockÃ©s sur S3.

---

## ğŸ“Œ Architecture Globale

```mermaid
graph TD
    subgraph "Data Source & Ingestion"
        A[S3 CSV] -->|Pull| B[Data Pull & Check]
        C[API Transactions] -->|Real-time| D[Predict]
    end

    subgraph "Airflow DAGs (Orchestration)"
        B[Data Pull & Check] --> E[ML Training]
        E --> F[Model Registry]
        D --> G[Email not.]
    end

    subgraph "MLflow (Model Management)"
        F[Model Registry] --> H[Metrics]
        F --> I[Artifact Model]
        H --> J[PostgreSQL NEON]
        I --> K[S3 Model]
    end

    subgraph "Output & Monitoring"
        G --> L[Anti Fraud Team Email]
        D --> M[S3 Predict Backup]
        M --> N[PostgreSQL NEON]
        N --> O[Streamlit Dashboard]
        O --> P[Dashboard for Anti Fraud Team Stakeholder]
    end

    %% Connexions externes
    style A fill:#FFD700,stroke:#333
    style C fill:#4CAF50,stroke:#333
    style B fill:#2196F3,stroke:#fff
    style D fill:#2196F3,stroke:#fff
    style E fill:#9C27B0,stroke:#fff
    style F fill:#FF9800,stroke:#fff
    style H fill:#8BC34A,stroke:#fff
    style I fill:#FF5722,stroke:#fff
    style J fill:#E91E63,stroke:#fff
    style K fill:#00BCD4,stroke:#fff
    style L fill:#FFEB3B,stroke:#333
    style M fill:#009688,stroke:#fff
    style N fill:#673AB7,stroke:#fff
    style O fill:#FF9800,stroke:#fff
    style P fill:#3F51B5,stroke:#fff

    %% FlÃ¨ches
    A --> B
    C --> D
    B --> E
    E --> F
    F --> H
    F --> I
    H --> J
    I --> K
    D --> G
    G --> L
    D --> M
    M --> N
    N --> O
    O --> P

    %% Labels
    A:::data-source
    C:::api-source
    B:::airflow-task
    D:::airflow-task
    E:::airflow-task
    F:::mlflow-component
    H:::mlflow-component
    I:::mlflow-component
    J:::storage
    K:::storage
    L:::notification
    M:::backup
    N:::storage
    O:::dashboard
    P:::stakeholder

    classDef data-source fill:#FFD700,stroke:#333,stroke-width:2px
    classDef api-source fill:#4CAF50,stroke:#333,stroke-width:2px
    classDef airflow-task fill:#2196F3,stroke:#fff,stroke-width:2px
    classDef mlflow-component fill:#FF9800,stroke:#fff,stroke-width:2px
    classDef storage fill:#673AB7,stroke:#fff,stroke-width:2px
    classDef notification fill:#FFEB3B,stroke:#333,stroke-width:2px
    classDef backup fill:#009688,stroke:#fff,stroke-width:2px
    classDef dashboard fill:#FF9800,stroke:#fff,stroke-width:2px
    classDef stakeholder fill:#3F51B5,stroke:#fff,stroke-width:2px

```


## ğŸ“‚ Structure du Projet

```
.
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ fraud_detection_datacheck.py         # DAG 1 : VÃ©rification qualitÃ© des donnÃ©es
â”‚   â”œâ”€â”€ fraud_detection_ml.py                # DAG 2 : Entrainement du modÃ¨le Xgboost et enregistrement dans MLFLOW
â”‚   â”œâ”€â”€ raud_detection_predict.py            # DAG 3 : Prediction temps rÃ©el d'un Fraude
â”‚   â””â”€â”€ fraud_detection_recap24h.py          # DAG 2 : Reporting 24h passÃ©es et envoie de notification par mail
â”œâ”€â”€ data/                                    # Dossier local pour les donnÃ©es (montÃ© dans Airflow)
â”‚   â”œâ”€â”€ fraudTest.csv                        # Dataset des transactions src : Kaggle
â”‚   â”œâ”€â”€ current_transactions_raw*.csv        # fichier brut src: API
â”‚   â”œâ”€â”€ current_transactions_clean*.csv      # Fichier nettoyÃ© prÃªt pour une prediction
â”‚   â””â”€â”€ fraud_detection_on_going.csv         # Fichier historique des prÃ©dictions
â”œâ”€â”€ reports/                                 # Rapports Evidently (Drift, Test Suite)
â””â”€â”€ README.md

```

## 1ï¸âƒ£ DAG evidently_data_quality_fraud

Objectif : VÃ©rifier la qualitÃ© des donnÃ©es avant l'entraÃ®nement.
FonctionnalitÃ©s :

- download_fraud_csv : TÃ©lÃ©charge le dataset fraudTest.csv depuis une URL.
- evidently_check : GÃ©nÃ¨re un rapport de drift (visuel) et une test suite (textuelle) avec Evidently.
- upload_reports_to_s3 : Sauvegarde les rapports en local et sur S3.
- send_evidently_report_email : Envoie un email de rÃ©sumÃ© avec les liens vers les rapports.
- trigger_xgboost_dag : DÃ©clenche le DAG suivant (fraud_detection_xgboost_dag) en passant le chemin du fichier CSV.

## 2ï¸âƒ£ DAG fraud_detection_xgboost_dag
Objectif : EntraÃ®ner un modÃ¨le XGBoost pour dÃ©tecter les fraudes.
FonctionnalitÃ©s :

- get_data : RÃ©cupÃ¨re le chemin du fichier CSV passÃ© par le DAG prÃ©cÃ©dent (dag_run.conf).
- clean_data : Nettoie les donnÃ©es (feature engineering, encodage, etc.).
- train_model : EntraÃ®ne un modÃ¨le XGBoost avec suivi des mÃ©triques via MLflow. Sauvegarde la matrice de confusion et log le modÃ¨le.

## Variable #Airflow

Variable,Description
- AWS_ACCESS_KEY_ID,ClÃ© AWS pour accÃ©der Ã  S3.
- AWS_SECRET_ACCESS_KEY,Secret AWS.
- BUCKET,Nom du bucket S3 pour les rapports.
- ARTIFACT_STORE_URI,URI du stockage MLflow.
- BACKEND_STORE_URI_FP,URI du backend MLflow.

## ğŸ”§ Comment Lancer le Pipeline ?
1. DÃ©ployer les DAGs

Copier les fichiers .py dans le dossier dags/ d'Airflow.
Activer les DAGs dans l'UI Airflow.

2. ExÃ©cuter manuellement (optionnel)

Dans l'UI Airflow, cliquer sur Trigger DAG pour evidently_data_quality_fraud.
Le DAG XGBoost sera dÃ©clenchÃ© automatiquement.

3. VÃ©rifier les rÃ©sultats

Rapports : Voir les emails envoyÃ©s ou les fichiers dans le bucket S3.
ModÃ¨le : Consulter l'expÃ©rience MLflow Ã  l'URL configurÃ©e.


âš ï¸ Points d'Attention

- DÃ©pendances : VÃ©rifier que toutes les librairies sont installÃ©es dans l'environnement Airflow.
- Permissions S3 : Le rÃ´le IAM doit avoir les droits s3:PutObject et s3:GetObject.
- MLflow : L'URI du tracking doit Ãªtre accessible depuis Airflow. MLFLOW est installÃ© sur Hugging Face dans un Docker 
- Chemin des fichiers : Le dossier /opt/airflow/data doit Ãªtre montÃ© et accessible en Ã©criture.