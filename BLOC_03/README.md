# Pipeline de DÃ©tection de Fraude avec Airflow, XGBoost et MLflow

Ce projet implÃ©mente un **pipeline automatisÃ© de dÃ©tection de fraude** en deux Ã©tapes :
1. **VÃ©rification de la qualitÃ© des donnÃ©es** (Drift, tests statistiques) avec Evidently.
2. **EntraÃ®nement d'un modÃ¨le XGBoost** et suivi des expÃ©riences avec MLflow.

Le pipeline est orchestrÃ© avec **Apache Airflow**, et les artefacts sont stockÃ©s sur S3.

---

## ğŸ“Œ Architecture Globale

```mermaid
graph TD
    %% === Sources de donnÃ©es ===
    A[S3 CSV] --> B[Data Pull & Check]
    C[API Transactions] --> D[Predict]

    %% === Nouvelle notification : Data Team ===
    B --> E[Email Alert to Data Team]

    %% === Orchestration Airflow ===
    B --> F[ML Training]
    F --> G[Model Registry]
    D --> H[Email Notification to Anti Fraud Team]

    %% === MLflow ===
    G --> I[Metrics]
    G --> J[Artifact Model]
    I --> K[PostgreSQL NEON]
    J --> L[S3 Model]

    %% === Sauvegarde & Monitoring ===
    D --> M[S3 Predict Backup]
    M --> N[PostgreSQL NEON]
    N --> O[Streamlit Dashboard]
    O --> P[Dashboard for Anti Fraud Team Stakeholder]

    %% === Styles sobres en gris ===
    classDef source fill:#f8f9fa,stroke:#666;
    classDef process fill:#f1f3f5,stroke:#666;
    classDef storage fill:#e9ecef,stroke:#666;
    classDef notification fill:#ffffff,stroke:#666,stroke-dasharray: 3 3;

    class A,C source
    class B,D,F,G,H,E,M,O process
    class K,L,N storage
    class H,E,P notification

```


## ğŸ“‚ Structure du Projet

```
.
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ fraud_detection_datacheck.py         # DAG 1 : VÃ©rification qualitÃ© des donnÃ©es
â”‚   â”œâ”€â”€ fraud_detection_ml.py                # DAG 2 : Entrainement du modÃ¨le Xgboost et enregistrement dans MLFLOW
â”‚   â”œâ”€â”€ raud_detection_predict.py            # DAG 3 : Prediction temps rÃ©el d'un Fraude
â”‚   â””â”€â”€ fraud_detection_recap24h.py          # DAG 2 : Reporting 24h passÃ©es et envoie de notification par mail
â”œâ”€â”€ data/                                    # Dossier local pour les donnÃ©es (montÃ© dans Airflow)
â”‚   â”œâ”€â”€ fraudTest.csv                        # Dataset des transactions src : Kaggle
â”‚   â”œâ”€â”€ current_transactions_raw*.csv        # fichier brut src: API
â”‚   â”œâ”€â”€ current_transactions_clean*.csv      # Fichier nettoyÃ© prÃªt pour une prediction
â”‚   â””â”€â”€ fraud_detection_on_going.csv         # Fichier historique des prÃ©dictions
â”œâ”€â”€ reports/                                 # Rapports Evidently (Drift, Test Suite)
â””â”€â”€ README.md

```

## 1ï¸âƒ£ DAG fraud_detection_01_evidently_data_quality

Objectif : VÃ©rifier la qualitÃ© des donnÃ©es avant l'entraÃ®nement.
FonctionnalitÃ©s :

- download_fraud_csv : TÃ©lÃ©charge le dataset fraudTest.csv depuis une URL.
- evidently_check : GÃ©nÃ¨re un rapport de drift (visuel) et une test suite (textuelle) avec Evidently.
- upload_reports_to_s3 : Sauvegarde les rapports en local et sur S3.
- send_evidently_report_email : Envoie un email de rÃ©sumÃ© avec les liens vers les rapports.
- trigger_xgboost_dag : DÃ©clenche le DAG suivant (fraud_detection_xgboost_dag) en passant le chemin du fichier CSV.

## 2ï¸âƒ£ DAG fraud_detection_02_xgboost_dag
Objectif : EntraÃ®ner un modÃ¨le XGBoost pour dÃ©tecter les fraudes.
FonctionnalitÃ©s :

- load_csv : RÃ©cupÃ¨re le chemin du fichier CSV passÃ© par le DAG prÃ©cÃ©dent (dag_run.conf).
- clean_data : Nettoie les donnÃ©es (feature engineering, encodage, etc.).
- train_mlflow : EntraÃ®ne un modÃ¨le XGBoost avec suivi des mÃ©triques via MLflow. Sauvegarde la matrice de confusion et log le modÃ¨le.

## 2ï¸âƒ£ DAG fraud_detection_03_prediction_api
Objectif : Faire une prÃ©diction en temps rÃ©el d'une Fraude .
FonctionnalitÃ©s :

- fetch_transactions : RÃ©cupÃ¨re la transaction qui vient de l'API.
- preprocess_data : Nettoie les donnÃ©es et les rend conforme au modÃ¨le d'entrainement
- predict_and_save : Faire une prÃ©diction avec le code Predict de MLFLOW et sauvegarder le rÃ©sultat dans un CSV mais aussi dans la Base Neon BD (PostgreSQL)
- upload_and_alert : Upload les rÃ©sultats dans un fichier CSV et envoie une notification Ã  l'Ã©quipe DATA

## Variable #Airflow

Variable,Description
- AWS_ACCESS_KEY_ID,ClÃ© AWS pour accÃ©der Ã  S3.
- AWS_SECRET_ACCESS_KEY,Secret AWS.
- BUCKET,Nom du bucket S3 pour les rapports.
- ARTIFACT_STORE_URI,URI du stockage MLflow.
- BACKEND_STORE_URI_FP,URI du backend MLflow.

## ğŸ”§ Comment Lancer le Pipeline ?
1. DÃ©ployer les DAGs

Copier les fichiers .py dans le dossier dags/ d'Airflow.
Activer les DAGs dans l'UI Airflow.

2. ExÃ©cuter manuellement (optionnel)

Dans l'UI Airflow, cliquer sur Trigger DAG pour evidently_data_quality_fraud.
Le DAG XGBoost sera dÃ©clenchÃ© automatiquement.

3. VÃ©rifier les rÃ©sultats

Rapports : Voir les emails envoyÃ©s ou les fichiers dans le bucket S3.
ModÃ¨le : Consulter l'expÃ©rience MLflow Ã  l'URL configurÃ©e.


âš ï¸ Points d'Attention

- DÃ©pendances : VÃ©rifier que toutes les librairies sont installÃ©es dans l'environnement Airflow.
- Permissions S3 : Le rÃ´le IAM doit avoir les droits s3:PutObject et s3:GetObject.
- MLflow : L'URI du tracking doit Ãªtre accessible depuis Airflow. MLFLOW est installÃ© sur Hugging Face dans un Docker 
- Chemin des fichiers : Le dossier /opt/airflow/data doit Ãªtre montÃ© et accessible en Ã©criture.