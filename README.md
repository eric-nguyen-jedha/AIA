# Pipeline de D√©tection de Fraude avec Airflow, XGBoost et MLflow

Ce projet impl√©mente un **pipeline automatis√© de d√©tection de fraude** en deux √©tapes :
1. **V√©rification de la qualit√© des donn√©es** (Drift, tests statistiques) avec Evidently.
2. **Entra√Ænement d'un mod√®le XGBoost** et suivi des exp√©riences avec MLflow.

Le pipeline est orchestr√© avec **Apache Airflow**, et les artefacts sont stock√©s sur S3.

---

## üìå Architecture Globale

```mermaid
graph TD
    A[evidently_data_quality_fraud] -->|Trigger + CSV| B[fraud_detection_xgboost_dag]
    A -->|Rapports| S3[Stockage S3]
    B -->|Mod√®le/Artifacts| MLflow[MLflow Tracking]
    B -->|Logs| Airflow[Logs Airflow]

```


## üìÇ Structure du Projet

```
.
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ evidently_data_quality_fraud.py      # DAG 1 : V√©rification qualit√© des donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ fraud_detection_xgboost_dag.py       # DAG 2 : Entra√Ænement XGBoost
‚îú‚îÄ‚îÄ data/                                    # Dossier local pour les donn√©es (mont√© dans Airflow)
‚îú‚îÄ‚îÄ reports/                                 # Rapports Evidently (Drift, Test Suite)
‚îî‚îÄ‚îÄ README.md

```

## 1Ô∏è‚É£ DAG evidently_data_quality_fraud

Objectif : V√©rifier la qualit√© des donn√©es avant l'entra√Ænement.
Fonctionnalit√©s :

- download_fraud_csv : T√©l√©charge le dataset fraudTest.csv depuis une URL.
- evidently_check : G√©n√®re un rapport de drift (visuel) et une test suite (textuelle) avec Evidently.
- upload_reports_to_s3 : Sauvegarde les rapports en local et sur S3.
- send_evidently_report_email : Envoie un email de r√©sum√© avec les liens vers les rapports.
- trigger_xgboost_dag : D√©clenche le DAG suivant (fraud_detection_xgboost_dag) en passant le chemin du fichier CSV.

## 2Ô∏è‚É£ DAG fraud_detection_xgboost_dag
Objectif : Entra√Æner un mod√®le XGBoost pour d√©tecter les fraudes.
Fonctionnalit√©s :

- get_data : R√©cup√®re le chemin du fichier CSV pass√© par le DAG pr√©c√©dent (dag_run.conf).
- clean_data : Nettoie les donn√©es (feature engineering, encodage, etc.).
- train_model : Entra√Æne un mod√®le XGBoost avec suivi des m√©triques via MLflow. Sauvegarde la matrice de confusion et log le mod√®le.

## Variable #Airflow

Variable,Description
- AWS_ACCESS_KEY_ID,Cl√© AWS pour acc√©der √† S3.
- AWS_SECRET_ACCESS_KEY,Secret AWS.
- BUCKET,Nom du bucket S3 pour les rapports.
- ARTIFACT_STORE_URI,URI du stockage MLflow.
- BACKEND_STORE_URI_FP,URI du backend MLflow.

## üîß Comment Lancer le Pipeline ?
1. D√©ployer les DAGs

Copier les fichiers .py dans le dossier dags/ d'Airflow.
Activer les DAGs dans l'UI Airflow.

2. Ex√©cuter manuellement (optionnel)

Dans l'UI Airflow, cliquer sur Trigger DAG pour evidently_data_quality_fraud.
Le DAG XGBoost sera d√©clench√© automatiquement.

3. V√©rifier les r√©sultats

Rapports : Voir les emails envoy√©s ou les fichiers dans le bucket S3.
Mod√®le : Consulter l'exp√©rience MLflow √† l'URL configur√©e.


‚ö†Ô∏è Points d'Attention

- D√©pendances : V√©rifier que toutes les librairies sont install√©es dans l'environnement Airflow.
- Permissions S3 : Le r√¥le IAM doit avoir les droits s3:PutObject et s3:GetObject.
- MLflow : L'URI du tracking doit √™tre accessible depuis Airflow.
- Chemin des fichiers : Le dossier /opt/airflow/data doit √™tre mont√© et accessible en √©criture.